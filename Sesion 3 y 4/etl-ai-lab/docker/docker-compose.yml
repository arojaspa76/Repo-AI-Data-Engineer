services:
  spark-master:
    image: bitnami/spark:3.5
    environment:
      - SPARK_MODE=master
    ports: ["7077:7077","8081:8080"]

  spark-worker:
    image: bitnami/spark:3.5
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on: [spark-master]

  airflow:
    image: apache/airflow:2.10.1
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW_CONN_SPARK_DEFAULT=spark://spark-master:7077
    volumes:
      - ../airflow:/opt/airflow
      - ../spark_jobs:/opt/spark_jobs
    working_dir: /opt/airflow
    command: bash -lc "pip install -r requirements.txt && airflow db init && \
                       airflow users create --username admin --firstname Andres --lastname Rojas \
                       --role Admin --email admin@triskel.ai --password admin123 && \
                       airflow webserver -p 8080 & airflow scheduler"
    ports: ["8080:8080"]
    depends_on: [spark-master, spark-worker]
